{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27862743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cead69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 17:00:50.527137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import pickle\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "import os\n",
    "import nrrd\n",
    "import mahotas as mh\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b8123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1f8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69f308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH= '/raid/mpsych/CACTAS/DATA/ESUS'\n",
    "CAPATH= '/raid/mpsych/CACTAS/DATA/CA24'\n",
    "path = '/raid/mpsych/CACTAS/DATA/HISTORY/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc26b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d81daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nrrd_files(file_list, DATAPATH, CAPATH):\n",
    "    img_files = []\n",
    "    seg_files = []\n",
    "    ca_files = []\n",
    "    for file in file_list:\n",
    "        img_file = os.path.join(DATAPATH, file)\n",
    "        \n",
    "        if file.endswith('.b.img.nrrd'):\n",
    "            seg_file = os.path.join(DATAPATH, file.replace('.b.img.nrrd', '.b.seg.nrrd'))\n",
    "            ca_file = os.path.join(CAPATH, file.replace('.b.img.nrrd', '.ca.seg.nrrd'))\n",
    "        else:\n",
    "            seg_file = os.path.join(DATAPATH, file.replace('.img.nrrd', '.b.seg.nrrd'))\n",
    "            ca_file = os.path.join(CAPATH, file.replace('.img.nrrd', '.ca.seg.nrrd'))\n",
    "\n",
    "        \n",
    "        img_data, img_header = nrrd.read(img_file)\n",
    "        img_files.append(img_data)\n",
    "        #print(img_file)\n",
    "        \n",
    "        if os.path.exists(seg_file):\n",
    "            seg_data, seg_header = nrrd.read(seg_file)\n",
    "            seg_files.append(seg_data)\n",
    "            #print(seg_file)\n",
    "        else:\n",
    "            print(\"cannot find label \" + file)\n",
    "        \n",
    "        if os.path.exists(ca_file):\n",
    "            ca_data, ca_header = nrrd.read(ca_file)\n",
    "            ca_files.append(ca_data)\n",
    "            #print(ca_file)\n",
    "        else:\n",
    "            print(\"cannot find ca mask \" + ca_file)\n",
    "    \n",
    "    return img_files, seg_files, ca_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ccfbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data_list):\n",
    "    normalized_data = []\n",
    "    for data in data_list:\n",
    "        min_val = np.min(data)\n",
    "        max_val = np.max(data)\n",
    "        normalized_data.append((data - min_val) / (max_val - min_val))\n",
    "    return normalized_data\n",
    "\n",
    "def slice_into_2d(img_list, seg_list, m_list):\n",
    "    slices = []\n",
    "    for i in range(len(img_list)):\n",
    "        data_array = np.array(img_list[i])\n",
    "        for z in range(data_array.shape[2]):\n",
    "            slice_2d = data_array[:, :, z]\n",
    "            slices.append(slice_2d)\n",
    "    slices_img = np.array(slices)\n",
    "            \n",
    "    slices1 = []\n",
    "    for i in range(len(seg_list)):\n",
    "        for z in range(seg_list[i].shape[2]):\n",
    "            slice_2d = seg_list[i][:, :, z]\n",
    "            slices1.append(slice_2d)\n",
    "\n",
    "    new_slices = []\n",
    "    for i in range(len(slices1)):\n",
    "        slices = np.where(slices1[i] != 0, True, False)\n",
    "        new_slices.append(slices)\n",
    "    slices_seg = np.array(new_slices)\n",
    "    \n",
    "    slices_mtrain=[]\n",
    "    for i in range(len(m_list)):\n",
    "        data_array = np.array(m_list[i])\n",
    "        for z in range(data_array.shape[2]):\n",
    "            slice_2d = data_array[:, :, z]\n",
    "            dilated = mh.dilate(slice_2d.astype(np.bool_))\n",
    "            for _ in range(9):\n",
    "                dilated = mh.dilate(dilated)\n",
    "            slices_mtrain.append(dilated)\n",
    "    slices_ca = np.array(slices_mtrain)\n",
    "    \n",
    "    slices_img = slices_img.reshape(slices_img.shape[0], slices_img.shape[1],slices_img.shape[2], 1)\n",
    "    slices_seg = slices_seg.reshape(slices_seg.shape[0], slices_seg.shape[1],slices_seg.shape[2], 1)\n",
    "    slices_ca = slices_ca.reshape(slices_ca.shape[0], slices_ca.shape[1],slices_ca.shape[2], 1)\n",
    "        \n",
    "    print(slices_img.shape, slices_seg.shape, slices_ca.shape)\n",
    "    \n",
    "    return slices_img, slices_seg, slices_ca\n",
    "\n",
    "def prepare_data(file_list, DATAPATH, CAPATH):\n",
    "    X, y, z = read_nrrd_files(file_list, DATAPATH, CAPATH)\n",
    "    \n",
    "    #shuffle data\n",
    "    data = list(zip(X, y, z))\n",
    "    np.random.shuffle(data)\n",
    "    X, y, z = zip(*data)\n",
    "    \n",
    "    # Normalize the data\n",
    "    X = normalize_data(X)\n",
    "    Z = normalize_data(z)    \n",
    "       \n",
    "    # Slice the 3D data into 2D slices\n",
    "    X_slices, y_slices, m_slices = slice_into_2d(X, y, Z)\n",
    "    \n",
    "    return X_slices, y_slices, m_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0691ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_image(X_train, m_train):\n",
    "    ## train image data + ca \n",
    "    train_masks=[]\n",
    "    for i in range(len(m_train)):\n",
    "        binary = (m_train[i] > 0).astype(np.uint8)\n",
    "        train_masks.append(binary)\n",
    "\n",
    "    train_images=[]\n",
    "    for i in range(len(X_train)):\n",
    "        train_image = X_train[i] * train_masks[i]\n",
    "        train_images.append(train_image)\n",
    "    train_images_array = np.array(train_images) \n",
    "\n",
    "    train_images_array = train_images_array.astype(np.float32)\n",
    "    train_images_array = train_images_array.reshape(train_images_array.shape[0], train_images_array.shape[1],train_images_array.shape[2], 1)\n",
    "\n",
    "    return train_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2705e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d269ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'unet_27/train_patient_order.pkl', 'rb') as f:\n",
    "    train_27 = pickle.load(f)\n",
    "\n",
    "with open(path + 'unet_27/test_patient_order.pkl', 'rb') as f:\n",
    "    test_27 = pickle.load(f)\n",
    "    \n",
    "with open(path + 'unet_27/training_history.pkl', 'rb') as f:\n",
    "    history_27 = pickle.load(f)\n",
    "\n",
    "with open(path + 'unet_27/experiment_data.pkl', 'rb') as f:\n",
    "    data_27 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513a9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/raid/mpsych/CACTAS/DATA/HISTORY/unet_27/unet_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cb7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30375ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13328, 512, 512, 1) (13328, 512, 512, 1) (13328, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, m_train = prepare_data(train_27, DATAPATH, CAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ecbe8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa92471",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "m_train = m_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3404680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_array = masked_image(X_train, m_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9443365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0fe584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = train_images_array\n",
    "y_data = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc9bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f92e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad309a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa9517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c88fbec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "#kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "losses = []\n",
    "ious = []\n",
    "iou_thresholds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc48cda4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 17:03:43.103784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-14 17:03:43.417905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2024-06-14 17:03:43.420559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2024-06-14 17:03:43.420580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-06-14 17:03:43.448647: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-06-14 17:03:43.448706: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-06-14 17:03:43.457777: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-14 17:03:43.461843: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-14 17:03:43.465004: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-06-14 17:03:43.471019: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-06-14 17:03:43.472584: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-06-14 17:03:43.484230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2024-06-14 17:03:43.484978: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 17:03:43.700484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2024-06-14 17:03:43.703099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2024-06-14 17:03:43.713394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2024-06-14 17:03:43.713961: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-06-14 17:03:44.592371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-14 17:03:44.592420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2024-06-14 17:03:44.592427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y \n",
      "2024-06-14 17:03:44.592431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N \n",
      "2024-06-14 17:03:44.606474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38425 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0)\n",
      "2024-06-14 17:03:44.610397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 38425 MB memory) -> physical GPU (device: 1, name: A100-SXM4-40GB, pci bus id: 0000:4e:00.0, compute capability: 8.0)\n",
      "2024-06-14 17:03:45.990628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-06-14 17:03:45.993699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2245740000 Hz\n",
      "2024-06-14 17:03:46.757260: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-06-14 17:03:47.621842: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2024-06-14 17:03:48.692224: W tensorflow/stream_executor/gpu/asm_compiler.cc:191] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2024-06-14 17:03:48.692250: W tensorflow/stream_executor/gpu/asm_compiler.cc:194] Used ptxas at ptxas\n",
      "2024-06-14 17:03:48.692752: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-06-14 17:03:48.788035: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-06-14 17:03:49.827945: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(X_data):\n",
    "    X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "    y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "    \n",
    "    model_27 = load_model(model_path, custom_objects={'iou': iou, 'iou_thresholded': iou_thresholded})\n",
    "    model_27.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou, iou_thresholded])\n",
    "    \n",
    "    scores = model_27.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    losses.append(scores[0])\n",
    "    ious.append(scores[1])\n",
    "    iou_thresholds.append(scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f7e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 6.1240363947945294e-06, Std IoU: 1.8010990658200576e-06, Mean IoU Threshold: 8.453580164768937e-07\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean IoU: {np.mean(ious)}, Std IoU: {np.std(ious)}, Mean IoU Threshold: {np.mean(iou_thresholds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4fc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78b08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c6f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0c827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2acc4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a5319b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "loo_results=[]\n",
    "counter = 0\n",
    "# max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207e9e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train_index, val_index in loo.split(X_data):\n",
    "#     if counter >= max_iterations:\n",
    "#         break\n",
    "        \n",
    "    X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "    y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    model_27 = load_model(model_path, custom_objects={'iou': iou, 'iou_thresholded': iou_thresholded})\n",
    "    model_27.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou, iou_thresholded])\n",
    "    scores = model_27.evaluate(X_val, y_val, verbose=0)\n",
    "    loo_results.append(scores[1])\n",
    "    \n",
    "#     counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3466f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 1.3484958641748264e-05, Std IoU: 4.1917188232228895e-05\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean IoU: {np.mean(loo_results)}, Std IoU: {np.std(loo_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090bda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5c01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db562c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100: Mean IoU: 7.635893061888056e-06, Std IoU: 5.895904461056821e-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#500: Mean IoU: 1.9095010140517843e-05, Std IoU: 6.982788610695563e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full: Mean IoU: 1.3484958641748264e-05, Std IoU: 4.1917188232228895e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f9db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576fc442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527e7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f062be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
